{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32bfb9b0",
   "metadata": {},
   "source": [
    "# Project: Web Page Phishing Detection using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f75d062",
   "metadata": {},
   "source": [
    "Goal: The goal of this project is to develop a machine learning-based system that can automatically detect phishing websites by analyzing their features, thereby enhancing cybersecurity and protecting users from fraudulent online activities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4260e",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "* NumPy (np): Used for mathematical operations like arrays, numbers, and calculations.\n",
    "\n",
    "* Pandas (pd): Used to handle and analyze data in table form (DataFrame).\n",
    "\n",
    "* Matplotlib & Seaborn: Used to create graphs, charts, and visualizations.\n",
    "\n",
    "* Warnings: Used to ignore unnecessary warning messages so the output looks clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98a5aa",
   "metadata": {},
   "source": [
    "### Data Loading & Preview\n",
    "* Load the phishing dataset into a DataFrame called data. \n",
    "* A DataFrame is like an Excel sheet with rows and columns.\n",
    "* data.head() shows the first 5 rows so we can preview the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('web-page-phishing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0663bc25",
   "metadata": {},
   "source": [
    "### Data Dimensions\n",
    "* df.shape shows the dataset size (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8573548d",
   "metadata": {},
   "source": [
    "### Data Summary\n",
    "* The .info() shows the number of entries (rows), the total number of columns, column name, the number of non-null values, and the data type (dtype) of the values in that column. \n",
    "* This helps in checking for missing data and ensuring the data types are correct for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c029b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55778f3",
   "metadata": {},
   "source": [
    "### Checking for Missing Values\n",
    "* The .isna() method checks every single cell in the DataFrame and returns True if a value is missing (like NaN) and False if it is not.\n",
    "* The .sum() gives a clear and simple overview of how many missing values exist in each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bad46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1379c",
   "metadata": {},
   "source": [
    "### Understanding the Target Variable\n",
    "* The .map() method is used to replace the numerical values in the 'phishing' column with more descriptive labels. In this case, 0 is changed to \"non-phishing\" and 1 is changed to \"phishing\".\n",
    "* The .value_counts() ives a clear overview of the number of phishing and non-phishing entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef07b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['phishing'].map({0: \"non-phishing\", 1: \"phishing\"}).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212846da",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "* Creating a Count Plot: The sns.countplot() function from the Seaborn library is used to create a bar chart\n",
    "* The bar chart shows that the number of websites classified as 0 (non-phishing) is significantly greater than the number of websites classified as 1 (phishing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc468a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='phishing', data=data, palette=\"Set2\")\n",
    "plt.title(\"Distribution of Phishing vs Legitimate Websites\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c019b9d",
   "metadata": {},
   "source": [
    "### Correlation Heatmap\n",
    "The heatmap visualizes the correlation matrix of the features, highlighting the relationships between different variables. This helps in identifying highly correlated features, which might be considered for dimensionality reduction or feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7238443",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(data.corr(), cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Correlation Heatmap of Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dae70d",
   "metadata": {},
   "source": [
    "* This code efficiently generates multiple plots at once by using a for loop to go through a list of features. For each feature, sns.histplot() creates a histogram to show the distribution of its values.\n",
    "* The plots reveal that for features like n_dots, n_hypens, n_slash, and n_redirection, the distributions for both classes are very similar and concentrated at low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['url_length','n_dots','n_hypens','n_slash','n_redirection']\n",
    "for col in features:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(data=data, x=col, hue=\"phishing\", kde=True, bins=40, palette=\"husl\")\n",
    "    plt.title(f\"Distribution of {col} by Class\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab3f95c",
   "metadata": {},
   "source": [
    "* Similar to the previous step, this code uses a for loop to create multiple plots efficiently. This time, it uses sns.boxplot() to create a box plot for each feature.\n",
    "* Each plot shows two boxes, one for non-phishing (class 0) and one for phishing (class 1).\n",
    "* The box itself represents the middle 50% of the data (from the 25th to the 75th percentile).\n",
    "* The line inside the box is the median (the 50th percentile).\n",
    "* The \"whiskers\" (lines extending from the box) show the general range of the data.\n",
    "* The individual dots or circles outside the whiskers are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bd2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.boxplot(x='phishing', y=col, data=data, palette=\"Set3\")\n",
    "    plt.title(f\"{col} vs Class\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd02ea4e",
   "metadata": {},
   "source": [
    "### Visualizing Data with PCA\n",
    "* This code cell prepares the data for Principal Component Analysis (PCA). It first separates the features (X) from the target variable (y).\n",
    "* The scatter plot shows the two principal components. Each point represents a website, with its color indicating whether it's a phishing (1) or non-phishing (0) website.\n",
    "* From the plot, we can see that the two classes are not clearly separable, with phishing and non-phishing websites largely mixed together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = data.drop('phishing', axis=1)\n",
    "y = data['phishing']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=pca_result[:,0], y=pca_result[:,1], hue=y, palette=\"Set1\", alpha=0.7)\n",
    "plt.title(\"PCA: Phishing vs Legitimate Websites\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208a1856",
   "metadata": {},
   "source": [
    "### Separating Features and Target\n",
    "*  The first line data_cleaned = data.dropna(subset=['phishing']) creates a new DataFrame by dropping any rows where the 'phishing' column has a missing value.\n",
    "* Features (X): The line X = data_cleaned.drop('phishing', axis=1) creates a new DataFrame X that contains all the columns except the 'phishing' column.\n",
    "* Target (y): The line y = data_cleaned['phishing'] creates a Series y that contains only the 'phishing' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.dropna(subset=['phishing'])\n",
    "X = data_cleaned.drop('phishing', axis=1)\n",
    "y = data_cleaned['phishing']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf45e841",
   "metadata": {},
   "source": [
    "### Splitting Data for Modeling\n",
    "* This is a critical step in machine learning. The train_test_split() function divides the dataset into two parts: a training set (80% of the data in this case) and a testing set (20%).\n",
    "* test_size=0.2: Specifies that 20% of the data will be used for the testing set.\n",
    "* random_state=42: This ensures that the split is the same every time you run the code, making the results reproducible.\n",
    "* stratify=y : t ensures that the proportion of phishing vs. non-phishing entries is the same in both the training and testing sets, providing a fair evaluation of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04627415",
   "metadata": {},
   "source": [
    "### Training and Evaluating Machine Learning Models\n",
    "* Importing Models: This code first imports three different machine learning models: Logistic Regression, Random Forest Classifier, and XGBoost Classifier. These models will be used to classify websites as either phishing or non-phishing.\n",
    "* Creating a Dictionary of Models: A dictionary named models is created to store the different model objects. Using a dictionary allows us to easily manage and iterate through each model.\n",
    "* Training and Evaluation Loop: The for loop automates the training and evaluation process for each model.\n",
    "* model.fit(): This line trains the model using the training data (X_train, y_train). The model learns patterns from this data.\n",
    "* model.predict(): This line uses the trained model to make predictions on the unseen test data (X_test).\n",
    "* accuracy_score(): This function compares the model's predictions (y_pred) to the actual values (y_test) to calculate the accuracy. Accuracy is a metric that tells us the percentage of correct predictions made by the model.\n",
    "* The output shows the accuracy for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca58bd",
   "metadata": {},
   "source": [
    "### Advanced Model Evaluation\n",
    "* Confusion Matrix: This table shows exactly where the model made mistakes. For example, in the Logistic Regression output, the top row shows that 11,935 non-phishing sites were correctly predicted, but 808 were incorrectly predicted as phishing.\n",
    "* Classification Report: This provides three key metrics for each class:\n",
    "* Precision: The model's accuracy when it predicts a certain class.\n",
    "* Recall: The model's ability to find all actual instances of a class.\n",
    "* F1-score: A balance between precision and recall, useful for imbalanced datasets.\n",
    "* The Random Forest model has slightly higher scores across all metrics, especially for the phishing class (1), which is the minority class. Its ROC-AUC score of 0.96 is also higher than Logistic Regression's 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0edb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    if y_proba is not None:\n",
    "        print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eeea09",
   "metadata": {},
   "source": [
    "### Cross-Validation for Robust Evaluation\n",
    "* This code uses k-fold cross-validation to get a more reliable and robust estimate of the models' performance. Instead of a single train-test split, the data is divided into cv=5 folds (or groups).\n",
    "* The output provides two numbers for each model:\n",
    "* Mean Accuracy: The average accuracy across all 5 folds. This is a more stable and reliable measure of the model's performance than a single test score.\n",
    "* Standard Deviation: This shows the variation in the accuracy scores across the folds. A low standard deviation indicates that the model's performance is consistent, while a high standard deviation suggests that its performance can vary depending on the data it's trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7eb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"{name} CV Mean Accuracy: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03c377",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with Grid Search\n",
    "* Hyperparameters are settings that are not learned from the data but are set by the data scientist (e.g., the number of trees in a Random Forest). We use GridSearchCV to automatically find the best combination of these settings.\n",
    "* The output shows the Best RF Params, which is the ideal combination of hyperparameters found by the search ('n_estimators': 200, 'max_depth': 20, etc.). It also shows the Best RF Score, which is the cross-validated accuracy achieved with this best combination, confirming that the tuning process successfully improved the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611aeb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Random Forest tuning\n",
    "rf_params = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), rf_params, cv=3, scoring=\"accuracy\", n_jobs=-1, verbose=2)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best RF Params:\", grid_rf.best_params_)\n",
    "print(\"Best RF Score:\", grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cea8332",
   "metadata": {},
   "source": [
    "## Final model evaluation\n",
    "\n",
    "Evaluate the best performing model (XGBoost) using a confusion matrix, classification report, and ROC-AUC score to provide a comprehensive understanding of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce0fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "best_model = models[\"XGBoost\"]\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"XGBoost Model Evaluation:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af30316",
   "metadata": {},
   "source": [
    "### Project Summary\n",
    "This project aimed to develop a machine learning model to detect phishing websites based on URL features.\n",
    "We performed data exploration, including examining the distribution of features and the target variable, checking for missing values, and visualizing correlations.\n",
    "We trained and evaluated three different models: Logistic Regression, Random Forest, and XGBoost.\n",
    "Based on the initial evaluation using accuracy on the test set, the XGBoost model achieved the highest accuracy of approximately 89.18%.\n",
    "Potential next steps include:\n",
    "- Further hyperparameter tuning for the best-performing models.\n",
    "- Exploring feature engineering techniques to create new relevant features.\n",
    "- Investigating more advanced methods for handling outliers and potential class imbalance.\n",
    "- Trying other advanced models such as neural networks.\n",
    "- Deploying the best model for real-time phishing detection.\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "\n",
    "*   The dataset contains information about websites, and the target variable 'phishing' indicates whether a website is phishing (1) or not (0).\n",
    "*   Initial model training showed that the XGBoost model achieved the highest accuracy (approximately 89.18%) on the test set compared to Logistic Regression (approximately 85.63%) and Random Forest (approximately 89.03%).\n",
    "*   The final evaluation of the XGBoost model using a confusion matrix, classification report, and ROC-AUC score provided a comprehensive understanding of its performance. The confusion matrix showed the counts of correct and incorrect predictions, the classification report provided precision, recall, and f1-score for each class, and the ROC-AUC score indicated the model's ability to distinguish between phishing and legitimate websites.\n",
    "\n",
    "### Insights or Next Steps\n",
    "\n",
    "*   While XGBoost performed best among the initial models, further hyperparameter tuning could potentially improve its performance.\n",
    "*   Exploring feature engineering or incorporating additional features could potentially lead to a more robust model for phishing detection."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
